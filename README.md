# AVESA Multi-Tenant Data Pipeline

A multi-tenant data ingestion and transformation pipeline supporting 30+ integration services, each with 10-20 endpoints. Built using AWS serverless technologies with canonical data modeling and SCD Type 2 historical tracking.

**Architecture Version:** 2.0.0 - Hybrid Account Strategy with Separate Canonical Transform Functions

## Architecture Overview

This pipeline uses a hybrid AWS account strategy with separate canonical transform functions:

### Hybrid Account Architecture
- **Production Account (563583517998):** Dedicated account for production workloads with enhanced security
- **Current Account (123938354448):** Development and staging environments only (production resources cleaned up June 2025)

### Pipeline Components
1. **Integration-Specific Lambda Functions**: Each integration service has its own dedicated lambda function that handles authentication, API calls, and data extraction for that specific service
2. **Separate Canonical Transform Functions**: Individual Lambda functions per canonical table for optimized processing:
   - `avesa-canonical-transform-tickets-{env}`
   - `avesa-canonical-transform-time-entries-{env}`
   - `avesa-canonical-transform-companies-{env}`
   - `avesa-canonical-transform-contacts-{env}`

### Scheduling Architecture
- **Hourly Ingestion:** ConnectWise ingestion runs every hour (00:00)
- **Staggered Canonical Transforms:**
  - Tickets: 15 minutes past hour (00:15)
  - Time Entries: 20 minutes past hour (00:20)
  - Companies: 25 minutes past hour (00:25)
  - Contacts: 30 minutes past hour (00:30)

## Integration Services

The pipeline is designed to support multiple integration services, each with its own lambda function:
- **ConnectWise** (PSA/RMM platform) - `avesa-connectwise-ingestion`
- **ServiceNow** (ITSM platform) - `avesa-servicenow-ingestion`
- **Salesforce** (CRM platform) - `avesa-salesforce-ingestion`
- **Microsoft 365** (Productivity suite) - `avesa-microsoft365-ingestion`
- **And 25+ more services...**

Each integration service lambda function handles:
- Service-specific authentication (OAuth, API keys, etc.)
- Service-specific API structures and rate limiting
- 10-20 different endpoints/tables per service
- Service-specific error handling and retry logic

## Project Structure

```
avesa/
â”œâ”€â”€ infrastructure/          # CDK infrastructure code
â”‚   â”œâ”€â”€ app.py              # CDK app entry point (hybrid account support)
â”‚   â”œâ”€â”€ stacks/             # CDK stack definitions
â”‚   â”‚   â”œâ”€â”€ data_pipeline_stack.py      # Main pipeline stack
â”‚   â”‚   â”œâ”€â”€ monitoring_stack.py         # Monitoring and alerting
â”‚   â”‚   â”œâ”€â”€ backfill_stack.py          # Backfill infrastructure
â”‚   â”‚   â””â”€â”€ cross_account_monitoring.py # Cross-account monitoring
â”‚   â””â”€â”€ constructs/         # Reusable CDK constructs
â”œâ”€â”€ src/                    # Lambda function source code
â”‚   â”œâ”€â”€ integrations/       # Integration-specific lambda functions
â”‚   â”‚   â”œâ”€â”€ connectwise/    # ConnectWise-specific ingestion lambda
â”‚   â”‚   â”œâ”€â”€ servicenow/     # ServiceNow-specific ingestion lambda (future)
â”‚   â”‚   â””â”€â”€ salesforce/     # Salesforce-specific ingestion lambda (future)
â”‚   â”œâ”€â”€ canonical_transform/ # Separate SCD2 transformation lambdas
â”‚   â”‚   â”œâ”€â”€ tickets/        # Tickets canonical transform
â”‚   â”‚   â”œâ”€â”€ time_entries/   # Time entries canonical transform
â”‚   â”‚   â”œâ”€â”€ companies/      # Companies canonical transform
â”‚   â”‚   â””â”€â”€ contacts/       # Contacts canonical transform
â”‚   â”œâ”€â”€ backfill/           # Backfill processing functions
â”‚   â””â”€â”€ shared/             # Shared utilities and libraries
â”œâ”€â”€ mappings/               # JSON mapping and configuration files
â”‚   â”œâ”€â”€ integrations/       # Integration service endpoint configurations
â”‚   â”‚   â”œâ”€â”€ connectwise_endpoints.json    # ConnectWise endpoints and settings
â”‚   â”‚   â”œâ”€â”€ servicenow_endpoints.json     # ServiceNow endpoints and settings
â”‚   â”‚   â””â”€â”€ salesforce_endpoints.json     # Salesforce endpoints and settings
â”‚   â”œâ”€â”€ canonical_mappings.json # Unified canonical schema definition
â”‚   â”œâ”€â”€ backfill_config.json    # Backfill configuration per service
â”‚   â”œâ”€â”€ tickets.json        # Canonical tickets table mapping
â”‚   â”œâ”€â”€ time_entries.json   # Canonical time entries table mapping
â”‚   â”œâ”€â”€ companies.json      # Canonical companies table mapping
â”‚   â””â”€â”€ contacts.json       # Canonical contacts table mapping
â”œâ”€â”€ scripts/                # Deployment and utility scripts
â”‚   â”œâ”€â”€ deploy-prod.sh           # Deploy to production account
â”‚   â”œâ”€â”€ deploy-dev-staging.sh    # Deploy to dev/staging environments
â”‚   â”œâ”€â”€ deploy-lambda-functions.py # Update Lambda functions
â”‚   â”œâ”€â”€ test-lambda-functions.py # Test pipeline functionality
â”‚   â”œâ”€â”€ setup-tenant.py         # Add new tenants
â”‚   â”œâ”€â”€ setup-service.py        # Add services to tenants
â”‚   â”œâ”€â”€ trigger-backfill.py     # Run backfill operations
â”‚   â””â”€â”€ setup-dev-environment.py # Set up dev environment
â”œâ”€â”€ docs/                   # Documentation
â”‚   â”œâ”€â”€ HYBRID_ACCOUNT_SETUP_GUIDE.md
â”‚   â”œâ”€â”€ BACKFILL_STRATEGY.md
â”‚   â”œâ”€â”€ PRODUCTION_MIGRATION_PHASE5_PHASE6_REPORT.md
â”‚   â”œâ”€â”€ PRODUCTION_CLEANUP_REPORT.md
â”‚   â””â”€â”€ MIGRATION_CHECKLIST.md
â”œâ”€â”€ tests/                  # Unit and integration tests
â”œâ”€â”€ ARCHITECTURE_TRANSFORMATION_SUMMARY.md # This transformation summary
â””â”€â”€ README_HYBRID_IMPLEMENTATION.md        # Hybrid implementation details
```

## Data Flow

```
ConnectWise API â†’ ConnectWise Lambda â†’ S3 (Raw Parquet)
ServiceNow API â†’ ServiceNow Lambda â†’ S3 (Raw Parquet)     â†’ Separate Canonical Transform Lambdas â†’ S3 (Canonical Parquet) â†’ Data Warehouse
Salesforce API â†’ Salesforce Lambda â†’ S3 (Raw Parquet)
```

### Canonical Transform Flow (Hourly + Staggered)
```
00:00 - ConnectWise Ingestion
00:15 - Tickets Canonical Transform
00:20 - Time Entries Canonical Transform
00:25 - Companies Canonical Transform
00:30 - Contacts Canonical Transform
```

## Storage Structure

### Raw Data
```
s3://{bucket}/{tenant_id}/raw/connectwise/{table_name}/{timestamp}.parquet
```

### Canonical Data
```
s3://{bucket}/{tenant_id}/canonical/{canonical_table}/{timestamp}.parquet
```

## Environment Architecture

### Production Account (563583517998)
- **Purpose:** Production workloads with enhanced security
- **Resources:** Clean naming without environment suffixes
  - DynamoDB: `TenantServices`, `LastUpdated`
  - S3: `data-storage-msp-prod`
  - Lambda: `avesa-{service}-prod`

### Current Account (123938354448)
- **Purpose:** Development and staging environments only
- **Status:** âœ… Production resources cleaned up (June 2025)
- **Resources:** Environment-suffixed naming
  - DynamoDB: `TenantServices-{env}`, `LastUpdated-{env}` (dev/staging only)
  - S3: `data-storage-msp-{env}` (dev/staging only)
  - Lambda: `avesa-{service}-{env}` (dev/staging only)

## Prerequisites

- AWS CLI configured
- Python 3.9+
- Node.js 18+ (for CDK)
- AWS CDK CLI installed (`npm install -g aws-cdk`)

## Quick Start

1. Install dependencies:
```bash
pip install -r requirements.txt
```

2. Deploy infrastructure:
```bash
./scripts/deploy-dev-staging.sh --environment dev
```

3. Create a tenant:
```bash
python scripts/setup-tenant.py \
  --tenant-id "example-tenant" \
  --company-name "Example Company" \
  --environment dev
```

4. Add services to the tenant:
```bash
# Add ConnectWise service
python scripts/setup-service.py \
  --tenant-id "example-tenant" \
  --service connectwise \
  --connectwise-url "https://api-na.myconnectwise.net" \
  --company-id "YourCompanyID" \
  --public-key "your-public-key" \
  --private-key "your-private-key" \
  --client-id "your-client-id" \
  --environment dev

# Add ServiceNow service (optional)
python scripts/setup-service.py \
  --tenant-id "example-tenant" \
  --service servicenow \
  --servicenow-instance "https://yourinstance.service-now.com" \
  --servicenow-username "your-username" \
  --servicenow-password "your-password" \
  --environment dev
```

5. Test the pipeline:
```bash
aws lambda invoke \
  --function-name avesa-connectwise-ingestion-dev \
  --payload '{"tenant_id": "example-tenant"}' \
  response.json
```

## Environment Variables

### Production Account (563583517998)
- `BUCKET_NAME`: `data-storage-msp-prod`
- `TENANT_SERVICES_TABLE`: `TenantServices`
- `LAST_UPDATED_TABLE`: `LastUpdated`
- `CDK_PROD_ACCOUNT`: `563583517998`

### Development/Staging (Current Account)
- `BUCKET_NAME`: `data-storage-msp-{env}`
- `TENANT_SERVICES_TABLE`: `TenantServices-{env}`
- `LAST_UPDATED_TABLE`: `LastUpdated-{env}`
- `CDK_DEFAULT_ACCOUNT`: Current account ID

## Key Features

### ğŸ—ï¸ Hybrid Account Architecture
- **Production Isolation**: Dedicated AWS account for production workloads
- **Development Simplicity**: Dev/staging remain in current account
- **Security Enhancement**: Complete separation of production data
- **Compliance Ready**: Foundation for SOC 2, ISO 27001 certifications

### ğŸ”„ Separate Canonical Transform Functions
- **Independent Scaling**: Each canonical table scales independently
- **Error Isolation**: Failures in one table don't affect others
- **Optimized Processing**: Table-specific optimizations and configurations
- **Parallel Execution**: Multiple transforms can run simultaneously

### â° Hourly Scheduling with Staggered Transforms
- **Simplified Scheduling**: Hourly ingestion instead of 15/30 minute intervals
- **Resource Optimization**: Staggered transforms prevent resource contention
- **Better Monitoring**: Clear separation of processing stages
- **Rate Limit Compliance**: Proper spacing to avoid API rate limits

### ğŸ“Š Enhanced Backfill Strategy
- **Automatic Detection**: Detects new services needing backfill
- **Chunked Processing**: 30-day chunks for efficient processing
- **Progress Tracking**: DynamoDB-based job tracking and resumption
- **Service Integration**: Seamless integration with canonical transforms

## Monitoring

### Production Monitoring
- **CloudWatch Dashboard**: `AVESA-DataPipeline-PROD`
- **Cross-Account Monitoring**: Monitor production from current account
- **SNS Alerts**: `arn:aws:sns:us-east-2:563583517998:avesa-alerts-prod`
- **Function-Level Metrics**: Individual metrics per canonical transform

### Development Monitoring
- **Environment-Specific Dashboards**: Separate monitoring per environment
- **Integrated Alerting**: Consolidated alerts across all environments
- **Log Insights**: Advanced querying and analysis capabilities